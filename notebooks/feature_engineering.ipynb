{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts.feature_engineering import compute_customer_metrics, extract_transaction_features, encode_categorical_columns, scale_numerical_columns\n",
    "from scripts.Default_estimator_WoE import calculate_rfms, create_default_estimator, visualize_rfms, woe_binning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data.csv\")\n",
    "aggregate_features = compute_customer_metrics(df)\n",
    "merged_df = pd.merge(df, aggregate_features , on = 'CustomerId')\n",
    "df = merged_df\n",
    "extracted_features = extract_transaction_features(df)\n",
    "# Define unimportant columns to drop\n",
    "unimportant_columns = [\n",
    "     'TransactionId', 'BatchId', 'AccountId', 'SubscriptionId',\n",
    "    'CustomerId', 'CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId',\n",
    "    'ProductCategory', 'ChannelId', 'TransactionStartTime', 'PricingStrategy',\n",
    "    'TransactionHour', 'TransactionDay', 'TransactionMonth', 'TransactionYear'\n",
    "]\n",
    "\n",
    "\n",
    "# Drop unimportant columns\n",
    "df_cleaned = df.drop(columns=unimportant_columns)\n",
    "\n",
    "# Output the cleaned dataframe\n",
    "print(\"Remaining columns after removing unimportant ones:\")\n",
    "print(df_cleaned.columns)\n",
    "\n",
    "# Save the cleaned dataframe to a new file (optional)\n",
    "df_cleaned.to_csv('data/cleaned_dataset1.csv', index=False)\n",
    "\n",
    "\n",
    "columns_to_one_hot_encode = [\"CurrencyCode\", \"ProviderId\", \"ProductId\", \"ProductCategory\", \"ChannelId\"]\n",
    "\n",
    "# Apply One-Hot Encoding to specified columns\n",
    "df = encode_categorical_columns(df, columns_to_one_hot_encode, encoding_type='onehot')\n",
    "print(\"One-Hot Encoded DataFrame:\")\n",
    "print(df)\n",
    "df = scale_numerical_columns(df,  [\"Amount\", \"Value\",\"TotalTransactionAmount\", \"AverageTransactionAmount\", \"TransactionCount\", \"TransactionStdDev\" ], \"normalize\")\n",
    "df = calculate_rfms(df)\n",
    "visualize_rfms(df)\n",
    "df = create_default_estimator(df)\n",
    "\n",
    "# Perform WoE binning on 'TotalTransactionAmount' as an example\n",
    "df = woe_binning(df, 'Label', 'TotalTransactionAmount')\n",
    "\n",
    "# Display resulting dataframe with calculated RFMS, Labels, and WoE\n",
    "# print(df[['TransactionId', 'RFMS_Score', 'Label', 'WoE']].head(20))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "df = df.drop(columns=['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 'CountryCode', 'ProviderId_ProviderId_1', 'ProviderId_ProviderId_2', 'ProviderId_ProviderId_3', 'ProviderId_ProviderId_4', 'ProviderId_ProviderId_5', 'ProviderId_ProviderId_6', 'ProductId_ProductId_1', 'ProductId_ProductId_10', 'ProductId_ProductId_11', 'ProductId_ProductId_12', 'ProductId_ProductId_13', 'ProductId_ProductId_14', 'ProductId_ProductId_15', 'ProductId_ProductId_16', 'ProductId_ProductId_19', 'ProductId_ProductId_2', 'ProductId_ProductId_20', 'ProductId_ProductId_21', 'ProductId_ProductId_22', 'ProductId_ProductId_23', 'ProductId_ProductId_24', 'ProductId_ProductId_27', 'ProductId_ProductId_3', 'ProductId_ProductId_4', 'ProductId_ProductId_5', 'ProductId_ProductId_6', 'ProductId_ProductId_7', 'ProductId_ProductId_8', 'ProductId_ProductId_9', 'ChannelId_ChannelId_1', 'ChannelId_ChannelId_2', 'ChannelId_ChannelId_3', 'ChannelId_ChannelId_5'])\n",
    "\n",
    "# Print the remaining columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_one_hot_encode = [\"Label\", \"bin\"]\n",
    "\n",
    "# Apply One-Hot Encoding to specified columns\n",
    "df = encode_categorical_columns(df, columns_to_one_hot_encode, encoding_type='onehot')\n",
    "print(\"One-Hot Encoded DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Data Splitting Function\n",
    "def split_data(df, target_column = \"Label\", test_size = 0.3, random_state =42):\n",
    "    \"\"\"Splits the dataframe into training and test sets.\"\"\"\n",
    "    y = df[target_column]\n",
    "    x = df.drop(columns = [target_column])\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= test_size, random_state= random_state)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Model Training Function\n",
    "def train_model(x_train, y_train, model_type = 'logistic'):\n",
    "    \"\"\"Trains a model based on the specified model type.\"\"\"\n",
    "    if model_type == 'logistic':\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "    elif model_type == 'decision_tree':\n",
    "        model = DecisionTreeClassifier()\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestClassifier()\n",
    "    elif model_type == 'gbm':\n",
    "        model = GradientBoostingClassifier()\n",
    "    else:\n",
    "        raise ValueError(\"Inbalid model type. Choose from ['logistic', 'decition_tree', 'random_forest', 'gbm']\")\n",
    "    \n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Hyperparameter Tuning Function\n",
    "def tune_hyperparameters(x_train, y_train, model, param_grid, search_type='grid', cv=5, n_iter= 10):\n",
    "    \"\"\"Tunes the model's hyperparameters using Grid Search or Random Search.\"\"\"\n",
    "    if search_type == 'grid':\n",
    "        search = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy')\n",
    "    elif search_type == 'random':\n",
    "        search = RandomizedSearchCV(model, param_grid, cv=cv, n_iter = n_iter, scoring= 'accuracy')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid search type. Choose 'grid' or 'random'\")\n",
    "    \n",
    "    search.fit(x_train, y_train)\n",
    "    return search.best_estimator_\n",
    "\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    \"\"\"Evaluates the model's performance on the test data.\"\"\"\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "\n",
    "# Main function to run the model traing and evaluation\n",
    "def run_model_training(df):\n",
    "    \"\"\"Runs the complet model selection, training, tuning, and evaluation pipeline.\"\"\"\n",
    "    # Split the data \n",
    "    x_train, x_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    #select two models for training\n",
    "    models = ['logistic', 'random_forest']\n",
    "\n",
    "\n",
    "    for model_type in models:\n",
    "        print(f\"\\nTranining {model_type} model...\")\n",
    "\n",
    "        #Train the model\n",
    "        model = train_model(x_train, y_train, model_type)\n",
    "        \n",
    "\n",
    "        #Define hyperparameter grid for tuning\n",
    "        if model_type == 'logistic':\n",
    "            param_grid ={'C':[0.01, 0.1, 1, 10]}\n",
    "        elif model_type == 'random_forest':\n",
    "            param_grid ={ 'n_estimators': [100, 200], 'max_depth': [10,20,30]}\n",
    "        \n",
    "\n",
    "        # Hyperparameter tuning\n",
    "        best_model = tune_hyperparameters(x_train, y_train, model, param_grid, search_type = 'grid')\n",
    "\n",
    "\n",
    "        # Evaluate the model \n",
    "        print(f\"\\nEvaluating {model_type} model after tuning...\")\n",
    "        evaluate_model(best_model, x_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_columns = [\"WoE\", \"bin\"\n",
    "]\n",
    "\n",
    "\n",
    "# Drop unimportant columns\n",
    "df = df.drop(columns=unimportant_columns)\n",
    "\n",
    "# Output the cleaned dataframe\n",
    "print(\"Remaining columns after removing unimportant ones:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_medians = df.median()\n",
    "df= df.fillna(column_medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tranining logistic model...\n",
      "\n",
      "Evaluating logistic model after tuning...\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       1.00      1.00      1.00     14051\n",
      "        Good       1.00      1.00      1.00     14434\n",
      "\n",
      "    accuracy                           1.00     28485\n",
      "   macro avg       1.00      1.00      1.00     28485\n",
      "weighted avg       1.00      1.00      1.00     28485\n",
      "\n",
      "\n",
      "Tranining random_forest model...\n",
      "\n",
      "Evaluating random_forest model after tuning...\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       1.00      1.00      1.00     14051\n",
      "        Good       1.00      1.00      1.00     14434\n",
      "\n",
      "    accuracy                           1.00     28485\n",
      "   macro avg       1.00      1.00      1.00     28485\n",
      "weighted avg       1.00      1.00      1.00     28485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_model_training(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
